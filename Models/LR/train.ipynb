{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "TrainTestDataDir = '/home/songyue/homeCredit/HomeCreditDefaultRisk/Data/TrainTestData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = 221\n",
    "OUTPUT_SIZE = 2\n",
    "LR = 0.0005\n",
    "EPOCHES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logistic_Regression, self).__init__()\n",
    "        self.logistic = nn.Linear(in_dim, n_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.logistic(x)\n",
    "        return out\n",
    "model = Logistic_Regression(220,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(DataName):\n",
    "    DataPath = os.path.join(TrainTestDataDir, DataName)\n",
    "    if not os.path.exists(DataPath):\n",
    "        print('%s does not exist!' % DataPath)\n",
    "        return\n",
    "    OriginData = pd.read_csv(DataPath, index_col=0)\n",
    "    OriginData = OriginData.sample(frac=1)#.reset_index(drop=True)  # 打乱顺序后返回\n",
    "    return OriginData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NormalData(TrainData, TestData):\n",
    "    # 对一些列的均值大于100的进行归一化处理\n",
    "    AllData = TrainData.append(TestData)\n",
    "    scaler = StandardScaler().fit(AllData)\n",
    "    TrainData = scaler.transform(TrainData)\n",
    "    return TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3105,  0.1790],\n",
      "        [-0.5584,  0.2571],\n",
      "        [ 0.1614, -0.1861],\n",
      "        [-0.8288, -0.4781],\n",
      "        [ 0.1354,  0.2466],\n",
      "        [ 0.1661,  0.0673],\n",
      "        [ 1.4951,  0.8405],\n",
      "        [-0.2260, -0.2616],\n",
      "        [ 0.9596, -0.0093],\n",
      "        [ 0.1497,  0.0263],\n",
      "        [-0.2153, -0.0447],\n",
      "        [ 0.1837,  0.2987],\n",
      "        [ 0.0690, -0.2174],\n",
      "        [ 0.9252,  0.5940],\n",
      "        [ 0.2108, -0.6449],\n",
      "        [ 0.0520,  0.6078],\n",
      "        [ 0.0852, -0.0520],\n",
      "        [-0.1126, -0.2945],\n",
      "        [-0.7352,  0.2104],\n",
      "        [-0.3423, -0.2860],\n",
      "        [ 1.0846,  0.5209],\n",
      "        [ 0.0579,  0.5049],\n",
      "        [-0.3805, -0.4361],\n",
      "        [ 0.0647, -0.4370],\n",
      "        [-0.1320,  0.3825],\n",
      "        [-0.1731,  0.2673],\n",
      "        [-0.1279, -0.0519],\n",
      "        [-0.4564, -0.0231],\n",
      "        [-0.4226, -1.1331],\n",
      "        [ 1.0501,  0.6704],\n",
      "        [-0.0482, -1.3414],\n",
      "        [ 0.0020,  0.1051]], device='cuda:0')\n",
      "tensor([[ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 1.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0.,  1.]], device='cuda:0')\n",
      "(tensor([ 0.1790,  0.2571,  0.1614, -0.4781,  0.2466,  0.1661,  1.4951,\n",
      "        -0.2260,  0.9596,  0.1497, -0.0447,  0.2987,  0.0690,  0.9252,\n",
      "         0.2108,  0.6078,  0.0852, -0.1126,  0.2104, -0.2860,  1.0846,\n",
      "         0.5049, -0.3805,  0.0647,  0.3825,  0.2673, -0.0519, -0.0231,\n",
      "        -0.4226,  1.0501, -0.0482,  0.1051], device='cuda:0'), tensor([ 1,  1,  0,  1,  1,  0,  0,  0,  0,  0,  1,  1,  0,  0,\n",
      "         0,  1,  0,  0,  1,  1,  0,  1,  0,  0,  1,  1,  1,  1,\n",
      "         0,  0,  0,  1], device='cuda:0'))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "log_softmax(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-962bea4f55b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#             print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-962bea4f55b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#             print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda2/envs/py3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda2/envs/py3/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 759\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda2/envs/py3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \"\"\"\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda2/envs/py3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: log_softmax(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    ModelDir = 'models'\n",
    "    ModelName = 'train1'\n",
    "    TrainDataName = ModelName + '.csv'\n",
    "    TestDataName = 'test.csv'\n",
    "    TrainData = loadData(TrainDataName)\n",
    "    TestData = loadData(TestDataName)\n",
    "    # 更改训练样本的index\n",
    "    TrainData.set_index('SK_ID_CURR', inplace=True)\n",
    "    TestData.set_index('SK_ID_CURR', inplace=True)\n",
    "    TrainTarget = TrainData.TARGET\n",
    "    TrainData.drop('TARGET', axis=1, inplace=True)\n",
    "    TrainData = NormalData(TrainData, TestData)\n",
    "    # 划分训练集和验证集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(TrainData,\n",
    "                                                      TrainTarget.values, test_size=0.1,\n",
    "                                                      random_state=711)\n",
    "    # 将他们转化为torch tensor\n",
    "    train_x = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "    train_y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    val_x = Variable(torch.from_numpy(X_val).type(\n",
    "        torch.FloatTensor), volatile=True).cuda()\n",
    "    val_y = Variable(torch.from_numpy(y_val).type(\n",
    "        torch.LongTensor), volatile=True).cuda()\n",
    "    \n",
    "    train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "    train_loader = Data.DataLoader(dataset=train_dataset,\n",
    "                                   batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    \n",
    "    # 开始训练\n",
    "    trainlosses = []\n",
    "    vallosses = []\n",
    "    rosscores = []\n",
    "    for epoch in range(EPOCHES):\n",
    "        trainaccTmp = []\n",
    "        trainlossTmp = []\n",
    "        for step, (b_x, b_y) in enumerate(train_loader):\n",
    "            b_x = Variable(b_x).type(torch.FloatTensor).cuda()\n",
    "            b_y_ans = Variable(b_y).type(torch.FloatTensor)\n",
    "            b_y = torch.zeros(b_y_ans.cpu().type(torch.LongTensor).unsqueeze(1).shape[0],2).scatter_(1,b_y_ans.cpu().type(torch.LongTensor).unsqueeze(1),1).cuda()\n",
    "            out = model(b_x).cuda()\n",
    "            print(out)\n",
    "            print(b_y)\n",
    "            print(torch.max(out,1))\n",
    "            loss = criterion(torch.max(out,1), b_y_ans)\n",
    "            \n",
    "#             print(loss)\n",
    "            \n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
